"""Streamlit entry point for the PPT translation prototype."""

from __future__ import annotations

import html
import io
import json
import logging
import math
import queue
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple
from zoneinfo import ZoneInfo

import streamlit as st
import streamlit.components.v1 as components
from PIL import Image

from src.chains.context_manager import ContextManager
from src.chains.translation_chain import create_translation_chain, translate_with_progress
from src.core.ppt_parser import PPTParser
from src.core.ppt_writer import PPTWriter
from src.core.text_extractor import ExtractionOptions, docs_to_markdown, extract_pptx_to_docs
from src.core.pdf_processor import PDFProcessor
from src.core.pdf_to_ppt_writer import PDFToPPTWriter, TextBoxStyle
from src.ui.extraction_settings import render_extraction_settings
from src.ui.file_handler import handle_upload
from src.ui.progress_tracker import ProgressTracker
from src.ui.settings_panel import render_settings
from src.utils.config import get_settings
from src.utils.glossary_loader import GlossaryLoader
from src.utils.helpers import chunk_paragraphs
from src.utils.repetition import build_repetition_plan, expand_translations
from src.utils.language_detector import LanguageDetector

logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(name)s: %(message)s")
LOGGER = logging.getLogger(__name__)

APP_ROOT_PATH = Path(__file__).resolve()
APP_BASE_DIR = APP_ROOT_PATH.parent
APP_TIMEZONE = ZoneInfo("Asia/Seoul")


def _compute_last_updated_date() -> str:
    """Resolve last updated date from Git, GitHub API, or file modification time."""

    # 1. Try Git
    try:
        git_output = subprocess.run(
            ["git", "log", "-1", "--format=%cd", "--date=short"],
            cwd=APP_BASE_DIR,
            capture_output=True,
            text=True,
            check=True,
        )
        last_commit_date = git_output.stdout.strip()
        if last_commit_date:
            return last_commit_date
    except (subprocess.CalledProcessError, FileNotFoundError):
        pass

    # 2. Try GitHub API (Fallback for cloud environments without .git)
    try:
        import urllib.request
        repo_api_url = "https://api.github.com/repos/Hyunsang-coder/ppt-translator"
        headers = {"User-Agent": "Streamlit-App-Metadata-Fetcher"}
        req = urllib.request.Request(repo_api_url, headers=headers)
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
            pushed_at = data.get("pushed_at")
            if pushed_at:
                return pushed_at[:10]  # Extract YYYY-MM-DD
    except Exception:
        pass

    # 3. Try File Modification Time (Fallback for offline/no-git environments)
    try:
        mtime = APP_ROOT_PATH.stat().st_mtime
        return datetime.fromtimestamp(mtime, tz=APP_TIMEZONE).strftime("%Y-%m-%d")
    except Exception:
        pass

    return datetime.now(APP_TIMEZONE).strftime("%Y-%m-%d")


APP_LAST_UPDATED = _compute_last_updated_date()

CAT_IMAGE_PATH = APP_BASE_DIR / "assets" / "ë²ˆì—­ìº£ íšŒìƒ‰.png"
try:
    resample = Image.Resampling.LANCZOS  # type: ignore[attr-defined]
except AttributeError:  # pragma: no cover - Pillow < 9 fallback
    resample = Image.LANCZOS

try:
    CAT_IMAGE = Image.open(CAT_IMAGE_PATH)
    CAT_IMAGE_SCALED = CAT_IMAGE.resize(
        (
            max(1, int(CAT_IMAGE.width * 0.7)),
            max(1, int(CAT_IMAGE.height * 0.7)),
        ),
        resample,
    )
except FileNotFoundError:  # pragma: no cover - asset expected to be present in prod
    CAT_IMAGE = None
    CAT_IMAGE_SCALED = None

st.set_page_config(page_title="PPT ë²ˆì—­ìº£", page_icon=CAT_IMAGE or "ğŸ“Š", layout="wide")

MAX_UI_LOG_LINES = 400
LOG_QUEUE_KEY = "ui_log_queue"
LOG_BUFFER_KEY = "ui_log_buffer"
LOG_DIRTY_KEY = "ui_log_dirty"
LOG_HANDLER_KEY = "ui_log_handler_attached"
EXTRACTION_STATE_KEY = "text_extraction_state"
PDF_CONVERSION_STATE_KEY = "pdf_conversion_state"


class StreamlitLogHandler(logging.Handler):
    """Thread-safe log handler that enqueues messages for the UI thread."""

    def __init__(self, target_queue: "queue.SimpleQueue[str]") -> None:
        super().__init__(level=logging.INFO)
        self._queue = target_queue
        self.setFormatter(logging.Formatter("[%(levelname)s] %(name)s: %(message)s"))

    def emit(self, record: logging.LogRecord) -> None:  # noqa: D401 - see class docstring
        try:
            message = self.format(record)
        except Exception:  # pragma: no cover - defensive
            return

        try:
            self._queue.put_nowait(message)
        except queue.Full:  # pragma: no cover - queue is unbounded but defensive check
            pass


def _initialise_log_state() -> tuple[queue.SimpleQueue[str], List[str]]:
    """Ensure session state contains queue and buffer for UI logs."""

    if LOG_QUEUE_KEY not in st.session_state:
        st.session_state[LOG_QUEUE_KEY] = queue.SimpleQueue()
    if LOG_BUFFER_KEY not in st.session_state:
        st.session_state[LOG_BUFFER_KEY] = []
    elif len(st.session_state[LOG_BUFFER_KEY]) > MAX_UI_LOG_LINES * 2:
        # Prevent excessive memory usage by clearing buffer if it exceeds 2x limit
        st.session_state[LOG_BUFFER_KEY] = []
    if LOG_DIRTY_KEY not in st.session_state:
        st.session_state[LOG_DIRTY_KEY] = True
    st.session_state.setdefault(LOG_HANDLER_KEY, False)
    return st.session_state[LOG_QUEUE_KEY], st.session_state[LOG_BUFFER_KEY]


def _drain_log_queue(target_buffer: List[str]) -> None:
    """Transfer queued log messages into the render buffer on the main thread."""

    message_queue: queue.SimpleQueue[str] = st.session_state[LOG_QUEUE_KEY]

    while True:
        try:
            message = message_queue.get_nowait()
        except queue.Empty:
            break
        target_buffer.append(message)

    if len(target_buffer) > MAX_UI_LOG_LINES:
        del target_buffer[: len(target_buffer) - MAX_UI_LOG_LINES]

    st.session_state[LOG_DIRTY_KEY] = True


def _render_log_panel(placeholder: Any, log_buffer: List[str]) -> None:
    """Render buffered logs inside the provided placeholder."""

    if not log_buffer:
        placeholder.info("ë¡œê·¸ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    else:
        placeholder.markdown("```\n" + "\n".join(log_buffer) + "\n```")
    st.session_state[LOG_DIRTY_KEY] = False


def _refresh_ui_logs(placeholder: Any, log_buffer: List[str]) -> None:
    """Drain queued logs and update the Streamlit panel if required."""

    _drain_log_queue(log_buffer)
    if st.session_state.get(LOG_DIRTY_KEY):
        _render_log_panel(placeholder, log_buffer)


def _approximate_tokens(text: str) -> int:
    """Rudimentary character-based token estimate for heuristics."""

    if not text:
        return 0
    return max(1, len(text) // 4)


def _estimate_tokens_for_batch(batch: Dict[str, object]) -> int:
    """Estimate total prompt tokens for a single translation batch."""

    texts = str(batch.get("texts", ""))
    ppt_context = str(batch.get("ppt_context", ""))
    glossary_terms = str(batch.get("glossary_terms", ""))

    token_estimate = (
        _approximate_tokens(texts)
        + _approximate_tokens(ppt_context)
        + _approximate_tokens(glossary_terms)
        + 200  # instructions + response padding
    )

    return max(1, token_estimate)


def _attach_streamlit_log_handler(log_queue: "queue.SimpleQueue[str]") -> None:
    """Attach the Streamlit log handler on the root logger once per session."""

    if st.session_state.get(LOG_HANDLER_KEY):
        return

    root_logger = logging.getLogger()
    root_logger.addHandler(StreamlitLogHandler(log_queue))
    st.session_state[LOG_HANDLER_KEY] = True


def _load_glossary(glossary_file) -> Tuple[dict[str, str] | None, str]:
    """Load glossary data from the uploaded file."""

    if glossary_file is None:
        return None, "None"

    glossary_loader = GlossaryLoader()
    glossary_bytes = io.BytesIO(glossary_file.getvalue())

    try:
        glossary = glossary_loader.load_glossary(glossary_bytes)
    except ValueError as exc:
        st.error(str(exc))
        return None, "None"

    st.success(f"ğŸ“š ìš©ì–´ì§‘ ë¡œë“œ ì™„ë£Œ: {len(glossary)}ê±´")
    return glossary, GlossaryLoader.format_glossary_terms(glossary)


def _determine_batch_size(total_paragraphs: int, settings) -> int:
    """Calculate a batch size that balances latency and throughput."""

    if total_paragraphs <= 0:
        return 1

    min_size = max(1, int(getattr(settings, "min_batch_size", 40)))
    max_size = max(min_size, int(getattr(settings, "max_batch_size", getattr(settings, "batch_size", min_size))))
    default_size = max(min_size, min(max_size, int(getattr(settings, "batch_size", max_size))))

    concurrency = max(1, int(getattr(settings, "max_concurrency", 1)))
    wave_multiplier = float(getattr(settings, "wave_multiplier", 1.2) or 1.2)
    wave_multiplier = max(1.0, wave_multiplier)

    target_batches = max(concurrency, int(math.ceil(concurrency * wave_multiplier * 2)))
    suggested_size = math.ceil(total_paragraphs / target_batches) if target_batches > 0 else default_size

    batch_size = max(min_size, min(max_size, suggested_size))
    if batch_size < default_size:
        batch_size = max(batch_size, min(default_size, max_size))

    actual_batches = max(1, math.ceil(total_paragraphs / batch_size))
    if actual_batches > 1:
        remainder = total_paragraphs - (actual_batches - 1) * batch_size
        if 0 < remainder < max(1, int(min_size * 0.5)):
            adjusted = math.ceil(total_paragraphs / (actual_batches - 1))
            batch_size = max(min_size, min(max_size, adjusted))

    return max(1, min(total_paragraphs, batch_size))


def _sanitize_for_filename(value: str, fallback: str) -> str:
    """Remove characters that are risky inside file names while keeping unicode."""

    from src.utils.security import sanitize_filename

    return sanitize_filename(value, fallback=fallback)


def _get_extraction_state() -> Dict[str, Any]:
    state = st.session_state.setdefault(EXTRACTION_STATE_KEY, {})
    state.setdefault("markdown", "")
    state.setdefault("file_name", None)
    state.setdefault("options", None)
    state.setdefault("slides", 0)
    state.setdefault("blocks", 0)
    state.setdefault("stale", False)
    return state


def _render_text_extraction_page(settings, extraction_options: ExtractionOptions) -> None:
    """Render PPT text extraction workflow."""

    st.title("ğŸ§¾ PPT í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    st.markdown("PPT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ Markdown í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    uploaded_file = st.file_uploader(
        "PPTX íŒŒì¼ ì—…ë¡œë“œ",
        type=["ppt", "pptx"],
        key="text_extraction_uploader",
        help="ìµœëŒ€ %dMBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤." % settings.max_upload_size_mb,
    )

    state = _get_extraction_state()
    current_signature = {
        "figures": extraction_options.figures,
        "charts": extraction_options.charts,
        "with_notes": extraction_options.with_notes,
    }

    if state["markdown"]:
        if uploaded_file and uploaded_file.name != state["file_name"]:
            state["stale"] = True
        elif state["options"] != current_signature:
            state["stale"] = True
        else:
            state["stale"] = False
    else:
        state["stale"] = False

    convert_clicked = st.button(
        "Markdown ë³€í™˜",
        type="primary",
        disabled=uploaded_file is None,
    )

    if convert_clicked and uploaded_file is not None:
        size_mb = uploaded_file.size / (1024 * 1024)
        if size_mb > settings.max_upload_size_mb:
            st.error(
                f"íŒŒì¼ í¬ê¸°ê°€ {settings.max_upload_size_mb}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ë” ì‘ì€ íŒŒì¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            ppt_buffer = io.BytesIO(uploaded_file.getvalue())
            ppt_buffer.seek(0)
            
            # Validate file signature
            from src.utils.security import validate_pptx_file, sanitize_filename
            is_valid, error_msg = validate_pptx_file(ppt_buffer)
            
            if not is_valid:
                st.error(error_msg or "íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. PPT ë˜ëŠ” PPTX íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                ppt_buffer.close()
            else:
                ppt_buffer.seek(0)
                try:
                    docs = extract_pptx_to_docs(ppt_buffer, extraction_options)
                    markdown_text = docs_to_markdown(docs, extraction_options)
                    total_blocks = sum(len(doc.blocks) for doc in docs)
                    sanitized_name = sanitize_filename(uploaded_file.name)
                    state.update(
                        {
                            "markdown": markdown_text,
                            "file_name": sanitized_name,
                            "options": current_signature,
                            "slides": len(docs),
                            "blocks": total_blocks,
                            "stale": False,
                        }
                    )
                    if markdown_text.strip():
                        st.success(f"ì´ {len(docs)}ê°œì˜ ìŠ¬ë¼ì´ë“œì—ì„œ {total_blocks}ê°œì˜ ë¸”ë¡ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as exc:  # pylint: disable=broad-except
                    LOGGER.exception("Extraction failed: %s", exc)
                    st.error("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                finally:
                    # Explicitly close buffer to free memory
                    ppt_buffer.close()

    if state["stale"]:
        st.info("ì˜µì…˜ì´ë‚˜ íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë³€í™˜ì„ ì‹¤í–‰í•˜ë©´ ìµœì‹  ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    markdown_value = state["markdown"]

    # ë²„íŠ¼ì„ ë¨¼ì € í‘œì‹œ
    if markdown_value.strip():
        safe_name = _sanitize_for_filename(Path(state["file_name"] or "presentation").stem, "presentation")
        download_name = f"{safe_name}_extracted.md"
        
        col1, col2 = st.columns([1, 1])
        with col1:
            st.download_button(
                "ğŸ“¥ Markdown ë‹¤ìš´ë¡œë“œ",
                data=markdown_value.encode("utf-8"),
                file_name=download_name,
                mime="text/markdown",
                use_container_width=True,
            )
        with col2:
            # JavaScriptë¥¼ ì‚¬ìš©í•œ í´ë¦½ë³´ë“œ ë³µì‚¬
            # JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì•ˆì „í•˜ê²Œ JavaScriptë¡œ ì „ë‹¬
            # ê¸¸ì´ ì œí•œì„ ì¶”ê°€í•˜ì—¬ XSS ë° DoS ë°©ì§€
            max_markdown_length = 10 * 1024 * 1024  # 10MB ì œí•œ
            safe_markdown = markdown_value[:max_markdown_length] if len(markdown_value) > max_markdown_length else markdown_value
            escaped_markdown = json.dumps(safe_markdown)
            
            # JSON ë¬¸ìì—´ ê¸¸ì´ í™•ì¸ (ê³¼ë„í•œ ê¸¸ì´ ë°©ì§€)
            if len(escaped_markdown) > 15 * 1024 * 1024:  # 15MB ì œí•œ (JSON ì´ìŠ¤ì¼€ì´í”„ ê³ ë ¤)
                st.warning("ë‚´ìš©ì´ ë„ˆë¬´ ì»¤ì„œ í´ë¦½ë³´ë“œ ë³µì‚¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                copy_html = """
                <div style="padding: 0.375rem 0.75rem; text-align: center; color: #6b7280;">
                    ë‚´ìš©ì´ ë„ˆë¬´ ì»¤ì„œ ë³µì‚¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤
                </div>
                """
            else:
                copy_html = f"""
                <!DOCTYPE html>
                <html>
                <head>
                    <style>
                        body {{
                            margin: 0;
                            padding: 0;
                            font-family: 'Source Sans Pro', sans-serif;
                        }}
                        button {{
                            width: 100%;
                            padding: 0.375rem 0.75rem;
                            background-color: rgb(255, 255, 255);
                            color: rgb(49, 51, 63);
                            border: 1px solid rgba(49, 51, 63, 0.2);
                            border-radius: 0.5rem;
                            font-family: 'Source Sans Pro', sans-serif;
                            font-size: 1rem;
                            font-weight: 400;
                            line-height: 1.6;
                            cursor: pointer;
                            transition: all 0.2s;
                        }}
                        button:hover {{
                            border-color: rgb(255, 75, 75);
                            color: rgb(255, 75, 75);
                        }}
                    </style>
                </head>
                <body>
                    <button onclick="copyToClipboard()">ğŸ“‹ í´ë¦½ë³´ë“œ ë³µì‚¬</button>
                    <script>
                        (function() {{
                            const text = {escaped_markdown};
                            
                            function copyToClipboard() {{
                                if (typeof navigator !== 'undefined' && navigator.clipboard && navigator.clipboard.writeText) {{
                                    navigator.clipboard.writeText(text).then(function() {{
                                        const btn = document.querySelector('button');
                                        if (btn) {{
                                            btn.textContent = 'âœ… ë³µì‚¬ ì™„ë£Œ!';
                                            setTimeout(function() {{
                                                btn.textContent = 'ğŸ“‹ í´ë¦½ë³´ë“œ ë³µì‚¬';
                                            }}, 2000);
                                        }}
                                    }}).catch(function(err) {{
                                        alert('ë³µì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
                                    }});
                                }} else {{
                                    alert('í´ë¦½ë³´ë“œ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                                }}
                            }}
                            
                            // ì „ì—­ í•¨ìˆ˜ë¡œ ë…¸ì¶œ
                            window.copyToClipboard = copyToClipboard;
                        }})();
                    </script>
                </body>
                </html>
                """
            components.html(copy_html, height=50)

    # ë¯¸ë¦¬ë³´ê¸°ë¥¼ ë²„íŠ¼ ì•„ë˜ì— í‘œì‹œ
    st.subheader("Markdown ë¯¸ë¦¬ë³´ê¸°")
    st.code(
        markdown_value,
        language="markdown",
        line_numbers=False,
    )


def _get_pdf_conversion_state() -> Dict[str, Any]:
    """Get or initialize PDF conversion state."""
    state = st.session_state.setdefault(PDF_CONVERSION_STATE_KEY, {})
    state.setdefault("result_buffer", None)
    state.setdefault("file_name", None)
    state.setdefault("pages_processed", 0)
    state.setdefault("text_blocks_count", 0)
    return state


def _render_pdf_conversion_settings(sidebar) -> Dict[str, Any]:
    """Render PDF to PPT conversion settings in sidebar."""
    sidebar.markdown("### PDF ë³€í™˜ ì„¤ì •")
    
    sidebar.info("ğŸ¤– OpenAI Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. API ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.")

    sidebar.markdown("#### í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìŠ¤íƒ€ì¼")

    use_auto_color = sidebar.checkbox(
        "ìë™ ìƒ‰ìƒ ë§¤ì¹­ (Adaptive Style)",
        value=True,
        help="ì›ë³¸ ì´ë¯¸ì§€ì˜ ë°°ê²½ìƒ‰ì„ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ìƒ‰ìƒì„ ìë™ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.",
    )

    if not use_auto_color:
        bg_color = sidebar.color_picker(
            "ë°°ê²½ìƒ‰",
            value="#FFFFFF",
            help="í…ìŠ¤íŠ¸ ë°•ìŠ¤ì˜ ë°°ê²½ìƒ‰ì„ ì„ íƒí•©ë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë®ìŠµë‹ˆë‹¤.",
        )

        text_color = sidebar.color_picker(
            "ê¸€ììƒ‰",
            value="#000000",
            help="í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ì„ íƒí•©ë‹ˆë‹¤.",
        )
    else:
        bg_color = None
        text_color = None

    font_name = sidebar.selectbox(
        "í°íŠ¸",
        options=["ë§‘ì€ ê³ ë”•", "Arial", "ë‚˜ëˆ”ê³ ë”•", "êµ´ë¦¼"],
        index=0,
        help="í…ìŠ¤íŠ¸ ë°•ìŠ¤ì— ì‚¬ìš©í•  í°íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.",
    )

    sidebar.markdown("#### ì´ë¯¸ì§€ ì„¤ì •")

    include_background = sidebar.checkbox(
        "ì›ë³¸ ë°°ê²½ ì´ë¯¸ì§€ í¬í•¨",
        value=False,
        help="ì²´í¬í•˜ë©´ PPT ìŠ¬ë¼ì´ë“œ ë°°ê²½ìœ¼ë¡œ ì›ë³¸ PDF ì´ë¯¸ì§€ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤.",
    )

    dpi = sidebar.slider(
        "ì´ë¯¸ì§€ í’ˆì§ˆ (DPI)",
        min_value=72,
        max_value=300,
        value=200,
        step=18,
        help="PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•  ë•Œì˜ í•´ìƒë„ì…ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤.",
    )

    return {
        "use_auto_color": use_auto_color,
        "bg_color": bg_color,
        "text_color": text_color,
        "font_name": font_name,
        "include_background": include_background,
        "dpi": dpi,
    }


def _hex_to_rgb(hex_color: str) -> Tuple[int, int, int]:
    """Convert hex color string to RGB tuple."""
    hex_color = hex_color.lstrip("#")
    return tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))


def _render_pdf_conversion_page(settings, conversion_settings: Dict[str, Any]) -> None:
    """Render PDF to PPT conversion workflow."""

    st.title("ğŸ“„ PDF â†’ PPT ë³€í™˜")
    st.markdown(
        "OpenAI Visionì„ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , "
        "ì›ë³¸ í˜ì´ì§€ë¥¼ ë°°ê²½ìœ¼ë¡œ í¸ì§‘ ê°€ëŠ¥í•œ PPTë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    )

    # Check API key
    if not settings.openai_api_key:
        st.error("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDF ë³€í™˜ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # Log panel setup
    log_panel = st.expander("ğŸ“œ ì‹¤í–‰ ë¡œê·¸", expanded=True)
    log_placeholder = log_panel.empty()
    log_queue, log_buffer = _initialise_log_state()
    _attach_streamlit_log_handler(log_queue)
    _refresh_ui_logs(log_placeholder, log_buffer)

    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=["pdf"],
        key="pdf_conversion_uploader",
        help="ìµœëŒ€ %dMBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤." % settings.max_upload_size_mb,
    )

    state = _get_pdf_conversion_state()

    # Check if file changed
    if uploaded_file:
        if state["file_name"] != uploaded_file.name:
            state["result_buffer"] = None
            state["file_name"] = uploaded_file.name
            state["pages_processed"] = 0
            state["text_blocks_count"] = 0

    convert_clicked = st.button(
        "ğŸ”„ PPTë¡œ ë³€í™˜",
        type="primary",
        disabled=uploaded_file is None,
    )

    if convert_clicked and uploaded_file is not None:
        size_mb = uploaded_file.size / (1024 * 1024)
        if size_mb > settings.max_upload_size_mb:
            st.error(
                f"íŒŒì¼ í¬ê¸°ê°€ {settings.max_upload_size_mb}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ë” ì‘ì€ íŒŒì¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            pdf_buffer = io.BytesIO(uploaded_file.getvalue())
            pdf_buffer.seek(0)

            with st.spinner("OpenAI Visionìœ¼ë¡œ PDFë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘... (í˜ì´ì§€ë‹¹ ì•½ 5-10ì´ˆ ì†Œìš”)"):
                try:
                    # Clear log buffer for fresh start
                    log_buffer.clear()
                    st.session_state[LOG_DIRTY_KEY] = True
                    _render_log_panel(log_placeholder, log_buffer)

                    # Initialize PDF processor
                    processor = PDFProcessor(
                        api_key=settings.openai_api_key,
                        model="gpt-5.1",
                        dpi=conversion_settings["dpi"],
                    )

                    # Process PDF
                    LOGGER.info("PDF ì²˜ë¦¬ ì‹œì‘ (Vision-First): %s", uploaded_file.name)
                    _refresh_ui_logs(log_placeholder, log_buffer)

                    ocr_results = processor.process_pdf(pdf_buffer)
                    _refresh_ui_logs(log_placeholder, log_buffer)

                    if not ocr_results:
                        st.warning("PDFì—ì„œ í˜ì´ì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return

                    # Create PPT with precise positioning
                    if conversion_settings["use_auto_color"]:
                        # Auto color: Pass None so backend uses adaptive logic
                        text_style = TextBoxStyle(
                            font_name=conversion_settings["font_name"],
                            background_color=None, # Signal for adaptive
                            text_color=None        # Signal for adaptive
                        )
                    else:
                        # Manual color
                        text_style = TextBoxStyle(
                            font_name=conversion_settings["font_name"],
                            background_color=_hex_to_rgb(conversion_settings["bg_color"]),
                            text_color=_hex_to_rgb(conversion_settings["text_color"]),
                        )

                    writer = PDFToPPTWriter(text_style=text_style)
                    output_buffer = writer.create_presentation(
                        ocr_results,
                        include_background=conversion_settings["include_background"]
                    )
                    _refresh_ui_logs(log_placeholder, log_buffer)

                    # Update state
                    total_blocks = sum(len(r.text_blocks) for r in ocr_results)
                    state["result_buffer"] = output_buffer
                    state["pages_processed"] = len(ocr_results)
                    state["text_blocks_count"] = total_blocks

                    LOGGER.info(
                        "ë³€í™˜ ì™„ë£Œ: %dí˜ì´ì§€, %dê°œ í…ìŠ¤íŠ¸ ë¸”ë¡",
                        len(ocr_results),
                        total_blocks,
                    )
                    _refresh_ui_logs(log_placeholder, log_buffer)

                    st.success(
                        f"âœ… ë³€í™˜ ì™„ë£Œ! {len(ocr_results)}í˜ì´ì§€ì—ì„œ {total_blocks}ê°œì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤."
                    )

                except ValueError as e:
                    LOGGER.error("ì„¤ì • ì˜¤ë¥˜: %s", e)
                    st.error(str(e))
                except ImportError as e:
                    LOGGER.error("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: %s", e)
                    st.error(
                        "í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                        "`pip install PyMuPDF langchain-openai` ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
                    )
                except Exception as exc:
                    LOGGER.exception("PDF ë³€í™˜ ì‹¤íŒ¨: %s", exc)
                    st.error("PDF ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                finally:
                    pdf_buffer.close()

    # Download button
    if state["result_buffer"] is not None:
        original_name = Path(state["file_name"] or "document").stem
        safe_name = _sanitize_for_filename(original_name, "document")
        timestamp = datetime.now().strftime("%Y%m%d")
        download_name = f"{safe_name}_converted_{timestamp}.pptx"

        st.download_button(
            label="ğŸ“¥ ë³€í™˜ëœ PPT ë‹¤ìš´ë¡œë“œ",
            data=state["result_buffer"].getvalue(),
            file_name=download_name,
            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
        )

        st.caption(
            f"ğŸ“Š {state['pages_processed']}í˜ì´ì§€, {state['text_blocks_count']}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡"
        )


def _render_translation_page(settings, settings_state: Dict[str, Any]) -> None:
    """Render PPT translation workflow."""

    st.title("ğŸŒ ë²ˆì—­ëœ PPT ìƒì„±")
    st.markdown("ì›ë³¸ PPTì˜ ë””ìì¸ì„ ìœ ì§€í•˜ë©´ì„œ ë‚´ë¶€ í…ìŠ¤íŠ¸ë§Œ ë²ˆì—­í•œ ìƒˆ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    if not settings.openai_api_key:
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë²ˆì—­ ì‹¤í–‰ ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    preprocess_repetitions = bool(settings_state.get("preprocess_repetitions"))
    if preprocess_repetitions:
        st.info("ë°˜ë³µ ë¬¸êµ¬ ì‚¬ì „ ì²˜ë¦¬ ì˜µì…˜ì´ í™œì„±í™”ë˜ì–´ ë™ì¼ ë¬¸ì¥ì„ í•œ ë²ˆë§Œ ë²ˆì—­í•©ë‹ˆë‹¤.")

    log_panel = st.expander("ğŸ“œ ì‹¤í–‰ ë¡œê·¸", expanded=True)
    log_placeholder = log_panel.empty()
    log_queue, log_buffer = _initialise_log_state()
    _attach_streamlit_log_handler(log_queue)
    _refresh_ui_logs(log_placeholder, log_buffer)

    uploaded_file = st.file_uploader(
        "PPT íŒŒì¼ ì—…ë¡œë“œ",
        type=["ppt", "pptx"],
        key="translation_uploader",
        help="ìµœëŒ€ %dMBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤." % settings.max_upload_size_mb,
    )

    ppt_buffer = None
    if uploaded_file:
        ppt_buffer = handle_upload(uploaded_file, max_size_mb=settings.max_upload_size_mb)
        _refresh_ui_logs(log_placeholder, log_buffer)

    if not ppt_buffer:
        return

    if st.button("ğŸš€ ë²ˆì—­ ì‹œì‘", type="primary"):
        with st.spinner("ë²ˆì—­ ì§„í–‰ ì¤‘..."):
            log_buffer.clear()
            while True:
                try:
                    log_queue.get_nowait()
                except queue.Empty:
                    break
            st.session_state[LOG_DIRTY_KEY] = True
            if st.session_state.get(LOG_HANDLER_KEY, False) is False:
                _attach_streamlit_log_handler(log_queue)
            _render_log_panel(log_placeholder, log_buffer)

            parser = PPTParser()
            ppt_buffer.seek(0)
            paragraphs, presentation = parser.extract_paragraphs(ppt_buffer)
            _refresh_ui_logs(log_placeholder, log_buffer)

            if not paragraphs:
                st.warning("ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            if len(presentation.slides) > 100:
                st.warning("ìŠ¬ë¼ì´ë“œê°€ 100ì¥ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            context_manager = ContextManager(paragraphs)
            ppt_context = context_manager.build_global_context()

            glossary, glossary_terms = _load_glossary(settings_state.get("glossary_file"))
            prepared_texts: List[str] = [info.original_text for info in paragraphs]
            if glossary:
                prepared_texts = GlossaryLoader.apply_glossary_to_texts(prepared_texts, glossary)

            repetition_plan = None
            target_paragraphs = paragraphs
            target_prepared_texts = prepared_texts

            if preprocess_repetitions:
                repetition_plan = build_repetition_plan(paragraphs)
                target_paragraphs = [paragraphs[idx] for idx in repetition_plan.unique_indices]
                target_prepared_texts = [prepared_texts[idx] for idx in repetition_plan.unique_indices]

                duplicates_info = repetition_plan.duplicate_counts()
                reduced = len(paragraphs) - len(target_paragraphs)
                if duplicates_info:
                    st.caption(
                        f"ë°˜ë³µ ë¬¸êµ¬ {len(duplicates_info)}ê°œ ê°ì§€: ë²ˆì—­ ë¬¸ì¥ ìˆ˜ {len(paragraphs)} â†’ {len(target_paragraphs)} (ê°ì†Œ {reduced})"
                    )
                    preview = sorted(duplicates_info.items(), key=lambda item: item[1], reverse=True)
                    with st.expander("ë°˜ë³µ ë¬¸êµ¬ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                        from src.utils.security import sanitize_html_content
                        
                        # ê° í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì´ìŠ¤ì¼€ì´í”„
                        safe_rows = []
                        for text, count in preview:
                            safe_text = sanitize_html_content(text, max_length=500)
                            safe_rows.append(f"<strong>{count}Ã—</strong>: {safe_text}")
                        
                        rows = "<br>".join(safe_rows)
                        st.markdown(
                            """
                            <div style="max-height: 280px; overflow-y: auto; padding-right: 6px;">
                                {rows}
                            </div>
                            """.format(rows=rows or "<em>ì¤‘ë³µ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.</em>"),
                            unsafe_allow_html=True,
                        )
                else:
                    st.caption("ë°˜ë³µ ë¬¸êµ¬ ì‚¬ì „ ì²˜ë¦¬ ê²°ê³¼ ì¤‘ë³µ ë¬¸ì¥ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                if not target_paragraphs:
                    st.warning("ë°˜ë³µ ë¬¸êµ¬ ì‚¬ì „ ì²˜ë¦¬ ê²°ê³¼ ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return

            detector = LanguageDetector()
            sample_text = "\n".join(paragraph.original_text for paragraph in paragraphs[:50])

            source_language = settings_state.get("source_lang")
            target_language = settings_state.get("target_lang")

            if source_language == "Auto":
                source_language = detector.detect_language(sample_text)
                st.info(f"ğŸ” ì†ŒìŠ¤ ì–¸ì–´ ê°ì§€: {source_language}")

            if target_language == "Auto":
                target_language = detector.infer_target_language(source_language)
                st.info(f"ğŸ” íƒ€ê²Ÿ ì–¸ì–´ ì¶”ë¡ : {target_language}")

            batch_size = _determine_batch_size(len(target_paragraphs), settings)

            batches = chunk_paragraphs(
                target_paragraphs,
                batch_size=batch_size,
                ppt_context=ppt_context,
                glossary_terms=glossary_terms,
                prepared_texts=target_prepared_texts,
            )

            LOGGER.info(
                "Prepared %d batches (batch size %d, unique paragraphs %d of %d total).",
                len(batches),
                batch_size,
                len(target_paragraphs),
                len(paragraphs),
            )
            _refresh_ui_logs(log_placeholder, log_buffer)

            if not batches:
                st.warning("ë²ˆì—­í•  ë°°ì¹˜ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

            estimated_tokens = _estimate_tokens_for_batch(batches[0])
            safe_concurrency = max(
                1,
                min(
                    int(settings.max_concurrency),
                    max(1, settings.tpm_limit // max(estimated_tokens, 1)),
                ),
            )

            LOGGER.info(
                "Estimated %d tokens per batch; using concurrency=%d (config max=%d, TPM limit=%d).",
                estimated_tokens,
                safe_concurrency,
                settings.max_concurrency,
                settings.tpm_limit,
            )
            _refresh_ui_logs(log_placeholder, log_buffer)

            st.caption(
                f"ë°°ì¹˜ í¬ê¸°: {batch_size} ë¬¸ì¥ (ê³ ìœ  {len(target_paragraphs)} / ì „ì²´ {len(paragraphs)}) | ìµœëŒ€ ë™ì‹œ ì‹¤í–‰: {safe_concurrency}"
            )

            progress_tracker = ProgressTracker(
                total_batches=len(batches),
                total_sentences=len(target_paragraphs),
                log_update_fn=lambda: _refresh_ui_logs(log_placeholder, log_buffer),
            )

            chain = create_translation_chain(
                model_name=settings_state.get("model", "gpt-5.1"),
                source_lang=source_language,
                target_lang=target_language,
                user_prompt=settings_state.get("user_prompt"),
            )

            try:
                LOGGER.info(
                    "Starting translation with concurrency=%d and model=%s.",
                    safe_concurrency,
                    settings_state.get("model", "gpt-5.1"),
                )
                _refresh_ui_logs(log_placeholder, log_buffer)
                translated_unique = translate_with_progress(
                    chain,
                    batches,
                    progress_tracker,
                    max_concurrency=safe_concurrency,
                )
            except Exception as exc:  # pylint: disable=broad-except
                LOGGER.exception("Translation failed: %s", exc)
                st.error("ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return

            if repetition_plan is not None:
                translated_texts = expand_translations(
                    repetition_plan,
                    translated_unique,
                    len(paragraphs),
                )
            else:
                translated_texts = translated_unique

            if glossary:
                translated_texts = [
                    GlossaryLoader.apply_glossary_to_translation(text, glossary)
                    for text in translated_texts
                ]

            writer = PPTWriter()
            output_buffer = writer.apply_translations(paragraphs, translated_texts, presentation)
            _refresh_ui_logs(log_placeholder, log_buffer)

            # Explicitly clear large objects to help GC
            paragraphs = None
            presentation = None
            translated_texts = None
            if repetition_plan is not None:
                translated_unique = None

            total_elapsed = progress_tracker.finish()
            minutes, seconds = divmod(total_elapsed, 60)
            LOGGER.info("Translation completed in %dë¶„ %.1fì´ˆ", int(minutes), seconds)
            _refresh_ui_logs(log_placeholder, log_buffer)
            st.success(f"âœ… ë²ˆì—­ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ")

            original_name = st.session_state.get("uploaded_ppt_name", "presentation")
            original_stem = Path(original_name).stem or "presentation"
            original_stem = _sanitize_for_filename(original_stem, "presentation")
            clean_model = _sanitize_for_filename(settings_state.get("model", "model"), "model")
            timestamp = datetime.now().strftime("%Y%m%d")
            safe_target_lang = _sanitize_for_filename(target_language, "target")
            download_name = f"{safe_target_lang}_{original_stem}_{clean_model}_{timestamp}.pptx"

            st.download_button(
                label="ğŸ“¥ ë²ˆì—­ëœ PPT ë‹¤ìš´ë¡œë“œ",
                data=output_buffer.getvalue(),
                file_name=download_name,
                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
            )


def main() -> None:
    """Render the Streamlit UI and orchestrate workflows."""

    settings = get_settings()

    st.sidebar.markdown(
        """
        <div style="text-align: center; font-size: 2rem; font-weight: 700; margin-bottom: 0.5rem;">
            PPT ë²ˆì—­ìº£
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.sidebar.markdown(
        f"""
        <div style="text-align: center; font-size: 0.9rem; color: #6b7280; margin-top: -0.25rem; margin-bottom: 0.5rem;">
            (Version 2.2, last updated: {APP_LAST_UPDATED})
        </div>
        """,
        unsafe_allow_html=True,
    )

    if CAT_IMAGE_SCALED is not None:
        st.sidebar.image(CAT_IMAGE_SCALED)
    elif CAT_IMAGE is not None:
        st.sidebar.image(CAT_IMAGE)

    st.sidebar.markdown("### ê¸°ëŠ¥ ì„ íƒ")
    feature = st.sidebar.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        options=("PPT ë²ˆì—­", "í…ìŠ¤íŠ¸ ì¶”ì¶œ", "PDF â†’ PPT ë³€í™˜"),
        index=0,
        label_visibility="collapsed",
    )

    if feature == "í…ìŠ¤íŠ¸ ì¶”ì¶œ":
        extraction_options = render_extraction_settings(st.sidebar)
        _render_text_extraction_page(settings, extraction_options)
    elif feature == "PDF â†’ PPT ë³€í™˜":
        conversion_settings = _render_pdf_conversion_settings(st.sidebar)
        _render_pdf_conversion_page(settings, conversion_settings)
    else:
        translation_settings = render_settings(st.sidebar)
        _render_translation_page(settings, translation_settings)


if __name__ == "__main__":
    main()
