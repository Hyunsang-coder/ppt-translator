"""Streamlit entry point for the PPT translation prototype."""

from __future__ import annotations

import io
import logging
import math
from datetime import datetime
from pathlib import Path
from typing import List, Tuple

import streamlit as st

from src.chains.context_manager import ContextManager
from src.chains.translation_chain import create_translation_chain, translate_with_progress
from src.core.image_optimizer import ImageOptimizer
from src.core.ppt_parser import PPTParser
from src.core.ppt_writer import PPTWriter
from src.ui.file_handler import get_cached_upload, handle_upload
from src.ui.progress_tracker import ProgressTracker
from src.ui.settings_panel import render_settings
from src.utils.config import get_settings
from src.utils.glossary_loader import GlossaryLoader
from src.utils.helpers import chunk_paragraphs
from src.utils.language_detector import LanguageDetector

logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(name)s: %(message)s")
LOGGER = logging.getLogger(__name__)

st.set_page_config(page_title="PPT Translator", page_icon="ğŸ“Š", layout="wide")


def _load_glossary(glossary_file) -> Tuple[dict[str, str] | None, str]:
    """Load glossary data from the uploaded file.

    Args:
        glossary_file: Streamlit uploaded file containing glossary definitions.

    Returns:
        Tuple of glossary mapping (or ``None``) and formatted string for prompts.
    """

    if glossary_file is None:
        return None, "None"

    glossary_loader = GlossaryLoader()
    glossary_bytes = io.BytesIO(glossary_file.getvalue())

    try:
        glossary = glossary_loader.load_glossary(glossary_bytes)
    except ValueError as exc:
        st.error(str(exc))
        return None, "None"

    st.success(f"ğŸ“š ìš©ì–´ì§‘ ë¡œë“œ ì™„ë£Œ: {len(glossary)}ê±´")
    return glossary, GlossaryLoader.format_glossary_terms(glossary)


def _determine_batch_size(total_paragraphs: int, settings) -> int:
    """Calculate a user-friendly batch size for translation."""

    if total_paragraphs <= 0:
        return 1

    max_batch_size = max(1, settings.batch_size)
    min_batch_size = max(1, getattr(settings, "min_batch_size", 40))
    target_batches = max(1, getattr(settings, "target_batch_count", 5))

    suggested = math.ceil(total_paragraphs / target_batches)
    batch_size = min(max_batch_size, max(min_batch_size, suggested))
    return max(1, min(total_paragraphs, batch_size))


def _sanitize_for_filename(value: str, fallback: str) -> str:
    """Remove characters that are risky inside file names while keeping unicode."""

    sanitized = "".join(ch for ch in value if ch.isalnum() or ch in ("-", "_"))
    return sanitized or fallback


def main() -> None:
    """Render the Streamlit UI and orchestrate the translation workflow."""

    settings = get_settings()
    if not settings.openai_api_key:
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë²ˆì—­ ì‹¤í–‰ ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.title("ğŸ“Š PowerPoint ë²ˆì—­ê¸°")
    st.markdown("LangChain + OpenAI GPT-5ë¥¼ í™œìš©í•œ ê³ í’ˆì§ˆ PPT ë²ˆì—­")

    uploaded_file = st.file_uploader("PPT íŒŒì¼ ì—…ë¡œë“œ", type=["ppt", "pptx"])

    ppt_buffer = None
    if uploaded_file:
        ppt_buffer = handle_upload(uploaded_file, max_size_mb=settings.max_upload_size_mb)

    if ppt_buffer:
        settings_state = render_settings()

        if st.button("ğŸš€ ë²ˆì—­ ì‹œì‘", type="primary"):
            with st.spinner("ë²ˆì—­ ì§„í–‰ ì¤‘..."):
                cached_buffer = get_cached_upload()
                if cached_buffer is None:
                    st.error("ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return

                parser = PPTParser()
                paragraphs, presentation = parser.extract_paragraphs(cached_buffer)

                if not paragraphs:
                    st.warning("ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return

                if len(presentation.slides) > 100:
                    st.warning("ìŠ¬ë¼ì´ë“œê°€ 100ì¥ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                context_manager = ContextManager(paragraphs)
                ppt_context = context_manager.build_global_context()

                glossary, glossary_terms = _load_glossary(settings_state.get("glossary_file"))
                prepared_texts: List[str] = [info.original_text for info in paragraphs]
                if glossary:
                    prepared_texts = GlossaryLoader.apply_glossary_to_texts(prepared_texts, glossary)

                detector = LanguageDetector()
                sample_text = "\n".join(paragraph.original_text for paragraph in paragraphs[:50])

                source_language = settings_state.get("source_lang")
                target_language = settings_state.get("target_lang")

                if source_language == "Auto":
                    source_language = detector.detect_language(sample_text)
                    st.info(f"ğŸ” ì†ŒìŠ¤ ì–¸ì–´ ê°ì§€: {source_language}")

                if target_language == "Auto":
                    target_language = detector.infer_target_language(source_language)
                    st.info(f"ğŸ” íƒ€ê²Ÿ ì–¸ì–´ ì¶”ë¡ : {target_language}")

                batch_size = _determine_batch_size(len(paragraphs), settings)
                st.caption(f"ë°°ì¹˜ í¬ê¸°: {batch_size} ë¬¸ì¥ (ì´ {len(paragraphs)} ë¬¸ì¥)")

                batches = chunk_paragraphs(
                    paragraphs,
                    batch_size=batch_size,
                    ppt_context=ppt_context,
                    glossary_terms=glossary_terms,
                    prepared_texts=prepared_texts,
                )

                if not batches:
                    st.warning("ë²ˆì—­í•  ë°°ì¹˜ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    return

                progress_tracker = ProgressTracker(
                    total_batches=len(batches), total_sentences=len(paragraphs)
                )

                chain = create_translation_chain(
                    model_name=settings_state.get("model", "gpt-5"),
                    source_lang=source_language,
                    target_lang=target_language,
                    user_prompt=settings_state.get("user_prompt"),
                )

                try:
                    translated_texts = translate_with_progress(chain, batches, progress_tracker)
                except Exception as exc:  # pylint: disable=broad-except
                    LOGGER.exception("Translation failed: %s", exc)
                    st.error("ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return

                if glossary:
                    translated_texts = [
                        GlossaryLoader.apply_glossary_to_translation(text, glossary)
                        for text in translated_texts
                    ]

                image_optimizer = ImageOptimizer()
                presentation = image_optimizer.optimise(presentation)

                writer = PPTWriter()
                output_buffer = writer.apply_translations(paragraphs, translated_texts, presentation)

                total_elapsed = progress_tracker.get_total_elapsed()
                minutes, seconds = divmod(total_elapsed, 60)
                LOGGER.info("Translation completed in %dë¶„ %.1fì´ˆ", int(minutes), seconds)
                st.success(f"âœ… ë²ˆì—­ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {int(minutes)}ë¶„ {seconds:.1f}ì´ˆ")

                original_name = st.session_state.get("uploaded_ppt_name", "presentation")
                original_stem = Path(original_name).stem or "presentation"
                original_stem = _sanitize_for_filename(original_stem, "presentation")
                clean_model = _sanitize_for_filename(settings_state.get("model", "model"), "model")
                timestamp = datetime.now().strftime("%Y%m%d")
                safe_target_lang = _sanitize_for_filename(target_language, "target")
                download_name = f"{safe_target_lang}_{original_stem}_{clean_model}_{timestamp}.pptx"

                st.download_button(
                    label="ğŸ“¥ ë²ˆì—­ëœ PPT ë‹¤ìš´ë¡œë“œ",
                    data=output_buffer.getvalue(),
                    file_name=download_name,
                    mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                )


if __name__ == "__main__":
    main()
